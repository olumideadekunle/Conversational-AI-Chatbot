{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olumideadekunle/Conversational-AI-Chatbot/blob/main/Conversational_AI_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural Language Processing\n",
        "## DeepTech\n",
        "\n",
        "# Olumide Adekunle"
      ],
      "metadata": {
        "id": "a9ORyIm2cZuF"
      },
      "id": "a9ORyIm2cZuF"
    },
    {
      "cell_type": "markdown",
      "id": "0af70856-1138-43e1-8d73-684f0f0163c4",
      "metadata": {
        "id": "0af70856-1138-43e1-8d73-684f0f0163c4"
      },
      "source": [
        "# Hands-On: Building a Simple Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "561a574f-ca1c-426f-9df4-fb40d28bfeac",
      "metadata": {
        "id": "561a574f-ca1c-426f-9df4-fb40d28bfeac"
      },
      "source": [
        "### Step 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b43d2f-511e-41a9-ab4d-f2011c8183b3",
      "metadata": {
        "id": "13b43d2f-511e-41a9-ab4d-f2011c8183b3"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import random\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c0bcbdb-f1fc-4abb-8b80-7b070f976ef4",
      "metadata": {
        "id": "3c0bcbdb-f1fc-4abb-8b80-7b070f976ef4"
      },
      "source": [
        "### Step 2: Simple Rule-Based Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb95d71-4492-4fd6-b0b8-7c181b8e6590",
      "metadata": {
        "id": "3bb95d71-4492-4fd6-b0b8-7c181b8e6590"
      },
      "outputs": [],
      "source": [
        "responses = {\n",
        "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Welcome!\"],\n",
        "    \"booking\": [\"Sure! What date would you prefer?\", \"When would you like to book?\"],\n",
        "    \"farewell\": [\"Goodbye!\", \"Have a great day!\"]\n",
        "}\n",
        "\n",
        "def chatbot_response(user_input):\n",
        "    if \"hello\" in user_input.lower():\n",
        "        return random.choice(responses[\"greeting\"])\n",
        "    elif \"book\" in user_input.lower():\n",
        "        return random.choice(responses[\"booking\"])\n",
        "    elif \"bye\" in user_input.lower():\n",
        "        return random.choice(responses[\"farewell\"])\n",
        "    else:\n",
        "        return \"I'm not sure I understand that.\"\n",
        "\n",
        "# Test the chatbot\n",
        "user_input = \"Hello, I want to book an appointment.\"\n",
        "print(\"Chatbot:\", chatbot_response(user_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955fae89-b529-41d0-bcbc-5be016a6c3e3",
      "metadata": {
        "id": "955fae89-b529-41d0-bcbc-5be016a6c3e3"
      },
      "source": [
        "# Hands-On with Hugging Face for Response Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fedbb18e-4bcd-45cf-9c9f-7706687c00ad",
      "metadata": {
        "id": "fedbb18e-4bcd-45cf-9c9f-7706687c00ad"
      },
      "source": [
        "### Step 1: Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58f0f23d-3da7-4b61-b860-4d2bd1fd04ed",
      "metadata": {
        "id": "58f0f23d-3da7-4b61-b860-4d2bd1fd04ed"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b77268a-cfc3-4b5f-9396-8c29b6bea69d",
      "metadata": {
        "id": "2b77268a-cfc3-4b5f-9396-8c29b6bea69d"
      },
      "source": [
        "### Step 2: Load a Pretrained Model for Chatbots\n",
        "Use a text-generation pipeline with GPT-2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394f815e-636c-4ec2-909f-a12bfea3a419",
      "metadata": {
        "id": "394f815e-636c-4ec2-909f-a12bfea3a419"
      },
      "outputs": [],
      "source": [
        "chatbot = pipeline(\"text-generation\", model=\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "383f1d9a-6a8f-4329-aa77-fab19d1e6559",
      "metadata": {
        "id": "383f1d9a-6a8f-4329-aa77-fab19d1e6559"
      },
      "source": [
        "### Step 3: Generate a Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5069b3d3-490b-45b0-bfef-aaf1343ebc30",
      "metadata": {
        "id": "5069b3d3-490b-45b0-bfef-aaf1343ebc30"
      },
      "outputs": [],
      "source": [
        "user_input = \"What is artificial intelligence?\"\n",
        "response = chatbot(user_input, max_length=50, num_return_sequences=1)\n",
        "print(\"Chatbot Response:\", response[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0bb209-679d-4858-8019-d9890795ab59",
      "metadata": {
        "id": "7b0bb209-679d-4858-8019-d9890795ab59"
      },
      "source": [
        "# Hands-On Chatbot Development with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788a4df9-a432-4167-b78a-d61ebdce3bb8",
      "metadata": {
        "id": "788a4df9-a432-4167-b78a-d61ebdce3bb8"
      },
      "source": [
        "#### Objective\n",
        "\n",
        "Build a chatbot using a pretrained transformer model for response generation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38c5baf2-b9ca-4cdb-9969-cda59f823677",
      "metadata": {
        "id": "38c5baf2-b9ca-4cdb-9969-cda59f823677"
      },
      "source": [
        "### Step 1: Load Pretrained Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e5cadb-3e6e-41c9-8cfe-783851988fd7",
      "metadata": {
        "id": "70e5cadb-3e6e-41c9-8cfe-783851988fd7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"microsoft/DialoGPT-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb48698-851c-46ef-9208-b704d29d9cde",
      "metadata": {
        "id": "3bb48698-851c-46ef-9208-b704d29d9cde"
      },
      "source": [
        "### Step 2: Tokenize User Input and Generate Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56dcc0c-b9bd-42f7-898c-a856b910c9f8",
      "metadata": {
        "id": "f56dcc0c-b9bd-42f7-898c-a856b910c9f8"
      },
      "outputs": [],
      "source": [
        "user_input = \"Hello! How are you?\"\n",
        "input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors=\"pt\")\n",
        "response_ids = model.generate(input_ids, max_length=50, pad_token_id=tokenizer.eos_token_id)\n",
        "response = tokenizer.decode(response_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "print(f\"Chatbot: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8e0dd30"
      },
      "source": [
        "# Task\n",
        "Enhance the existing chatbot by implementing intent recognition and entity extraction, managing conversation context, evaluating its performance with relevant metrics, developing a simple interactive user interface, and creating comprehensive project documentation including a README, project name, description, presentation outline, and an architectural diagram. Finally, review all components to ensure a well-rounded and professionally presented project."
      ],
      "id": "b8e0dd30"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5e6c48"
      },
      "source": [
        "## Implement Intent Recognition and Entity Extraction\n",
        "\n",
        "### Subtask:\n",
        "Enhance the chatbot's understanding by adding a layer for identifying user intent (e.g., 'booking', 'greeting') and extracting key entities (e.g., 'date', 'product'). This can be done using libraries like SpaCy or by training a small classifier.\n"
      ],
      "id": "6a5e6c48"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "437d0b08"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to expand the existing `responses` dictionary and create a new `recognize_intent` function. I will update the `responses` dictionary with more intents and then define the `recognize_intent` function to identify these intents based on user input keywords. This will enhance the chatbot's ability to classify user queries.\n",
        "\n"
      ],
      "id": "437d0b08"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7f486eb"
      },
      "source": [
        "responses = {\n",
        "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Welcome!\"],\n",
        "    \"booking\": [\"Sure! What date would you prefer?\", \"When would you like to book?\"],\n",
        "    \"farewell\": [\"Goodbye!\", \"Have a great day!\"],\n",
        "    \"product_inquiry\": [\"Which product are you interested in?\", \"Tell me more about the product you're looking for.\"],\n",
        "    \"support\": [\"How can I assist you with support?\", \"Please describe your issue.\"],\n",
        "    \"unknown\": [\"I'm not sure I understand that.\"]\n",
        "}\n",
        "\n",
        "def recognize_intent(user_input):\n",
        "    user_input_lower = user_input.lower()\n",
        "    if \"hello\" in user_input_lower or \"hi\" in user_input_lower:\n",
        "        return \"greeting\"\n",
        "    elif \"book\" in user_input_lower or \"appointment\" in user_input_lower:\n",
        "        return \"booking\"\n",
        "    elif \"bye\" in user_input_lower or \"goodbye\" in user_input_lower:\n",
        "        return \"farewell\"\n",
        "    elif \"product\" in user_input_lower or \"item\" in user_input_lower:\n",
        "        return \"product_inquiry\"\n",
        "    elif \"support\" in user_input_lower or \"help\" in user_input_lower or \"issue\" in user_input_lower:\n",
        "        return \"support\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Test the intent recognition\n",
        "print(\"Intent for 'Hello, I want to book an appointment.':\", recognize_intent(\"Hello, I want to book an appointment.\"))\n",
        "print(\"Intent for 'I need help with my product.':\", recognize_intent(\"I need help with my product.\"))\n",
        "print(\"Intent for 'Tell me about an item.':\", recognize_intent(\"Tell me about an item.\"))\n",
        "print(\"Intent for 'See you later!':\", recognize_intent(\"See you later!\"))\n",
        "print(\"Intent for 'What is your name?':\", recognize_intent(\"What is your name?\"))"
      ],
      "id": "c7f486eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d74446de"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the subtask instructions, the next step is to install the SpaCy library and download the `en_core_web_sm` English language model. This is necessary for entity extraction in later steps.\n",
        "\n"
      ],
      "id": "d74446de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c52f88e"
      },
      "source": [
        "get_ipython().system('pip install spacy && python -m spacy download en_core_web_sm')"
      ],
      "id": "3c52f88e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc544eff"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to import the SpaCy library, load the `en_core_web_sm` model, and define the `extract_entities` function as per the subtask instructions. This function will use SpaCy to identify and return named entities from user input.\n",
        "\n"
      ],
      "id": "dc544eff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ad5fc5"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(user_input):\n",
        "    doc = nlp(user_input)\n",
        "    entities = {}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ not in entities:\n",
        "            entities[ent.label_] = []\n",
        "        entities[ent.label_].append(ent.text)\n",
        "    return entities\n",
        "\n",
        "# Test the entity extraction\n",
        "print(\"Entities for 'I want to book a meeting for tomorrow at 3 PM about the new product launch.':\", extract_entities(\"I want to book a meeting for tomorrow at 3 PM about the new product launch.\"))\n",
        "print(\"Entities for 'Can I get support for my iPhone on July 20th?':\", extract_entities(\"Can I get support for my iPhone on July 20th?\"))\n",
        "print(\"Entities for 'I am looking for a new laptop.':\", extract_entities(\"I am looking for a new laptop.\"))"
      ],
      "id": "d4ad5fc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7909f601"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to modify the `chatbot_response` function to incorporate both `recognize_intent` and `extract_entities` for generating more intelligent responses, as per the subtask instructions.\n",
        "\n"
      ],
      "id": "7909f601"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "837fe250"
      },
      "source": [
        "def chatbot_response(user_input):\n",
        "    intent = recognize_intent(user_input)\n",
        "    entities = extract_entities(user_input)\n",
        "\n",
        "    response_text = random.choice(responses.get(intent, responses[\"unknown\"]))\n",
        "\n",
        "    if intent == \"booking\" and \"DATE\" in entities:\n",
        "        date = entities[\"DATE\"][0]\n",
        "        response_text += f\" How about {date}?\"\n",
        "    elif intent == \"product_inquiry\" and (\"PRODUCT\" in entities or \"NORP\" in entities):\n",
        "        product = entities.get(\"PRODUCT\", entities.get(\"NORP\", [\"\"]))[0]\n",
        "        response_text += f\" Can you tell me more about the {product}?\"\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# Test the enhanced chatbot\n",
        "print(\"Chatbot (greeting + booking entities):\", chatbot_response(\"Hello, I'd like to book an appointment for tomorrow.\"))\n",
        "print(\"Chatbot (product inquiry with product entity):\", chatbot_response(\"I'm looking for an iPhone.\"))\n",
        "print(\"Chatbot (simple farewell):\", chatbot_response(\"Goodbye.\"))\n",
        "print(\"Chatbot (unknown intent):\", chatbot_response(\"What is the weather like?\"))\n"
      ],
      "id": "837fe250",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74a43b82"
      },
      "source": [
        "## Implement Conversation Context Management\n",
        "\n",
        "### Subtask:\n",
        "Modify the chatbot to maintain conversation history across multiple turns, allowing it to respond more coherently and remember previous interactions.\n"
      ],
      "id": "74a43b82"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7d603e"
      },
      "source": [
        "**Reasoning**:\n",
        "To implement conversation context management, I need to define `conversation_history`, modify the `chatbot_response` function to accept and update this history, and add logic to use the history for more coherent responses, especially for the 'booking' intent where a date might be missing from the current input.\n",
        "\n"
      ],
      "id": "3a7d603e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1848091"
      },
      "source": [
        "conversation_history = []\n",
        "\n",
        "def chatbot_response(user_input, history):\n",
        "    intent = recognize_intent(user_input)\n",
        "    entities = extract_entities(user_input)\n",
        "\n",
        "    # Append current user input to history\n",
        "    history.append({\"role\": \"user\", \"text\": user_input})\n",
        "\n",
        "    response_text = random.choice(responses.get(intent, responses[\"unknown\"]))\n",
        "\n",
        "    # Enhanced logic for booking intent\n",
        "    if intent == \"booking\":\n",
        "        date_found = False\n",
        "        if \"DATE\" in entities:\n",
        "            date = entities[\"DATE\"][0]\n",
        "            response_text = random.choice(responses[\"booking\"]) + f\" How about {date}?\"\n",
        "            date_found = True\n",
        "        else:\n",
        "            # Check conversation history for a date if not found in current input\n",
        "            for entry in reversed(history):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"DATE\" in prev_entities:\n",
        "                        date = prev_entities[\"DATE\"][0]\n",
        "                        response_text = random.choice(responses[\"booking\"]) + f\" Based on our previous chat, how about {date}?\"\n",
        "                        date_found = True\n",
        "                        break\n",
        "            if not date_found:\n",
        "                response_text = random.choice(responses[\"booking\"]) + \" What date would you prefer?\"\n",
        "    elif intent == \"product_inquiry\" and (\"PRODUCT\" in entities or \"NORP\" in entities):\n",
        "        product = entities.get(\"PRODUCT\", entities.get(\"NORP\", [\"\"]))[0]\n",
        "        if product: # Ensure product is not empty\n",
        "             response_text = random.choice(responses[\"product_inquiry\"]) + f\" Can you tell me more about the {product}?\"\n",
        "        else:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"])\n",
        "    else:\n",
        "        response_text = random.choice(responses.get(intent, responses[\"unknown\"]))\n",
        "\n",
        "    # Append chatbot response to history\n",
        "    history.append({\"role\": \"chatbot\", \"text\": response_text})\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# Test the enhanced chatbot with conversation history\n",
        "conversation_history = []\n",
        "\n",
        "print(\"User: Hello, I'd like to book an appointment.\")\n",
        "resp = chatbot_response(\"Hello, I'd like to book an appointment.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: I want it for next Tuesday.\")\n",
        "resp = chatbot_response(\"I want it for next Tuesday.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: I'm looking for an iPhone.\")\n",
        "resp = chatbot_response(\"I'm looking for an iPhone.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: Goodbye.\")\n",
        "resp = chatbot_response(\"Goodbye.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: What is the weather like?\")\n",
        "resp = chatbot_response(\"What is the weather like?\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"Full Conversation History:\", conversation_history)"
      ],
      "id": "d1848091",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26076bda"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block for context management did not fully achieve the desired behavior, particularly for follow-up questions related to booking dates and product inquiries. The `recognize_intent` function's order of checks caused specific intents like 'booking' to be overlooked if 'greeting' keywords were also present. Additionally, the `chatbot_response` function's logic needed to more explicitly leverage the previous conversation turn's intent when the current intent is 'unknown' but contains relevant entities. This refined code addresses these issues by reordering intent recognition, adding specific product keywords to intent recognition, and enhancing the `chatbot_response` to consider historical intent for better context handling.\n",
        "\n"
      ],
      "id": "26076bda"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "306afe02"
      },
      "source": [
        "responses = {\n",
        "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Welcome!\"],\n",
        "    \"booking\": [\"Sure! What date would you prefer?\", \"When would you like to book?\"],\n",
        "    \"farewell\": [\"Goodbye!\", \"Have a great day!\"],\n",
        "    \"product_inquiry\": [\"Which product are you interested in?\", \"Tell me more about the product you're looking for.\"],\n",
        "    \"support\": [\"How can I assist you with support?\", \"Please describe your issue.\"],\n",
        "    \"unknown\": [\"I'm not sure I understand that.\"]\n",
        "}\n",
        "\n",
        "def recognize_intent(user_input):\n",
        "    user_input_lower = user_input.lower()\n",
        "    # Prioritize more specific intents first\n",
        "    if \"book\" in user_input_lower or \"appointment\" in user_input_lower:\n",
        "        return \"booking\"\n",
        "    elif \"product\" in user_input_lower or \"item\" in user_input_lower or \"iphone\" in user_input_lower or \"laptop\" in user_input_lower:\n",
        "        return \"product_inquiry\"\n",
        "    elif \"support\" in user_input_lower or \"help\" in user_input_lower or \"issue\" in user_input_lower:\n",
        "        return \"support\"\n",
        "    elif \"hello\" in user_input_lower or \"hi\" in user_input_lower:\n",
        "        return \"greeting\"\n",
        "    elif \"bye\" in user_input_lower or \"goodbye\" in user_input_lower:\n",
        "        return \"farewell\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def chatbot_response(user_input, history):\n",
        "    current_intent = recognize_intent(user_input)\n",
        "    current_entities = extract_entities(user_input)\n",
        "\n",
        "    # Determine effective intent, considering history\n",
        "    effective_intent = current_intent\n",
        "    if current_intent == \"unknown\" and history:\n",
        "        last_user_entry = None\n",
        "        for entry in reversed(history): # Iterate backwards to find the last user input\n",
        "            if entry[\"role\"] == \"user\":\n",
        "                last_user_entry = entry\n",
        "                break\n",
        "        if last_user_entry:\n",
        "            last_user_intent = recognize_intent(last_user_entry[\"text\"])\n",
        "            # If the last user input had a booking intent and current input has a DATE entity, assume booking\n",
        "            if last_user_intent == \"booking\" and \"DATE\" in current_entities:\n",
        "                effective_intent = \"booking\"\n",
        "            # If the last user input had a product inquiry intent and current input has a PRODUCT/NORP entity, assume product_inquiry\n",
        "            elif last_user_intent == \"product_inquiry\" and (\"PRODUCT\" in current_entities or \"NORP\" in current_entities):\n",
        "                effective_intent = \"product_inquiry\"\n",
        "\n",
        "    # Append current user input to history\n",
        "    history.append({\"role\": \"user\", \"text\": user_input})\n",
        "\n",
        "    response_text = random.choice(responses.get(effective_intent, responses[\"unknown\"])) # Default response based on effective intent\n",
        "\n",
        "    # Logic for booking intent\n",
        "    if effective_intent == \"booking\":\n",
        "        date_found = False\n",
        "        date = None\n",
        "        if \"DATE\" in current_entities:\n",
        "            date = current_entities[\"DATE\"][0]\n",
        "            response_text = random.choice(responses[\"booking\"]) + f\" How about {date}?\"\n",
        "            date_found = True\n",
        "        elif not date_found:\n",
        "            # Check conversation history for a date if not found in current input\n",
        "            # Exclude the very last entry (current user input) from history search for previous date\n",
        "            for entry in reversed(history[:-1]):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"DATE\" in prev_entities:\n",
        "                        date = prev_entities[\"DATE\"][0]\n",
        "                        response_text = random.choice(responses[\"booking\"]) + f\" Based on our previous chat, how about {date}?\"\n",
        "                        date_found = True\n",
        "                        break\n",
        "            if not date_found:\n",
        "                response_text = random.choice(responses[\"booking\"]) + \" What date would you prefer?\"\n",
        "\n",
        "    # Logic for product inquiry intent\n",
        "    elif effective_intent == \"product_inquiry\":\n",
        "        product = None\n",
        "        if \"PRODUCT\" in current_entities:\n",
        "            product = current_entities[\"PRODUCT\"][0]\n",
        "        elif \"NORP\" in current_entities: # Sometimes product names might be tagged as NORP (Nationalities, Religious or Political Groups) or other entities if SpaCy doesn't know them.\n",
        "            product = current_entities[\"NORP\"][0]\n",
        "        else: # Check history for product if not found in current or current_entities\n",
        "             for entry in reversed(history[:-1]):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"PRODUCT\" in prev_entities:\n",
        "                        product = prev_entities[\"PRODUCT\"][0]\n",
        "                        break\n",
        "                    elif \"NORP\" in prev_entities: # Also check for NORP in history for product names\n",
        "                        product = prev_entities[\"NORP\"][0]\n",
        "                        break\n",
        "\n",
        "        if product:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"]) + f\" Can you tell me more about the {product}?\"\n",
        "        else:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"])\n",
        "\n",
        "    # Append chatbot response to history\n",
        "    history.append({\"role\": \"chatbot\", \"text\": response_text})\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# Test the enhanced chatbot with conversation history\n",
        "conversation_history = []\n",
        "\n",
        "print(\"User: Hello, I'd like to book an appointment.\")\n",
        "resp = chatbot_response(\"Hello, I'd like to book an appointment.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: I want it for next Tuesday.\")\n",
        "resp = chatbot_response(\"I want it for next Tuesday.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: I'm looking for an iPhone.\")\n",
        "resp = chatbot_response(\"I'm looking for an iPhone.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: Goodbye.\")\n",
        "resp = chatbot_response(\"Goodbye.\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"User: What is the weather like?\")\n",
        "resp = chatbot_response(\"What is the weather like?\", conversation_history)\n",
        "print(\"Chatbot:\", resp)\n",
        "\n",
        "print(\"Full Conversation History:\", conversation_history)"
      ],
      "id": "306afe02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83833e9a"
      },
      "source": [
        "## Evaluate Chatbot Performance\n",
        "\n",
        "### Subtask:\n",
        "Introduce methods to evaluate the chatbot's responses. This could include using metrics like BLEU or ROUGE for quality of generation, or setting up a framework for human evaluation to assess relevance and naturalness. Note to provide metrics and evaluation results.\n"
      ],
      "id": "83833e9a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fdeafc5"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to install the `nltk` library, which is required for calculating BLEU scores, a metric for evaluating text generation quality.\n",
        "\n"
      ],
      "id": "5fdeafc5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61c07511"
      },
      "source": [
        "get_ipython().system('pip install nltk')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(\"NLTK and punkt tokenizer downloaded and ready for use.\")"
      ],
      "id": "61c07511",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b50a70a"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to create test cases, define an evaluation function using BLEU score, and then apply it to assess the chatbot's performance, as per the instructions.\n",
        "\n"
      ],
      "id": "6b50a70a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdf6f03d"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 2. Create a list of test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"user_input\": \"Hello, I'd like to book an appointment.\",\n",
        "        \"reference_response\": \"When would you like to book? What date would you prefer?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I want it for next Tuesday.\",\n",
        "        \"reference_response\": \"When would you like to book? How about next Tuesday?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I'm looking for an iPhone.\",\n",
        "        \"reference_response\": \"Which product are you interested in?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Goodbye.\",\n",
        "        \"reference_response\": \"Have a great day!\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"What is the weather like?\",\n",
        "        \"reference_response\": \"I'm not sure I understand that.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I need help with my laptop.\",\n",
        "        \"reference_response\": \"How can I assist you with support? Please describe your issue.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Can you book a meeting for tomorrow?\",\n",
        "        \"reference_response\": \"When would you like to book? How about tomorrow?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 3. Define an evaluation function\n",
        "def evaluate_chatbot(test_case):\n",
        "    user_input = test_case[\"user_input\"]\n",
        "    reference_response = test_case[\"reference_response\"]\n",
        "\n",
        "    # Use a fresh history for each test case to avoid cross-contamination\n",
        "    current_conversation_history = []\n",
        "    chatbot_actual_response = chatbot_response(user_input, current_conversation_history)\n",
        "\n",
        "    # Tokenize responses for BLEU score calculation\n",
        "    # The reference is a list of lists of tokens (or single list if only one reference)\n",
        "    # The candidate is a single list of tokens\n",
        "    reference_tokens = [word_tokenize(reference_response.lower())]\n",
        "    candidate_tokens = word_tokenize(chatbot_actual_response.lower())\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    # Weights are for 1-gram, 2-gram, 3-gram, 4-gram. Adjust as needed.\n",
        "    # For short sentences, using higher order n-grams might result in 0.0 scores.\n",
        "    # Using uniform weights for simplicity.\n",
        "    score = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    return chatbot_actual_response, score\n",
        "\n",
        "# 4. Iterate through the test cases and print BLEU scores\n",
        "bleu_scores = []\n",
        "print(\"--- Chatbot Evaluation Results ---\")\n",
        "for i, tc in enumerate(test_cases):\n",
        "    actual_response, score = evaluate_chatbot(tc)\n",
        "    bleu_scores.append(score)\n",
        "    print(f\"\\nTest Case {i+1}:\")\n",
        "    print(f\"  User Input: '{tc['user_input']}'\")\n",
        "    print(f\"  Reference:  '{tc['reference_response']}'\")\n",
        "    print(f\"  Chatbot:    '{actual_response}'\")\n",
        "    print(f\"  BLEU Score: {score:.4f}\")\n",
        "\n",
        "# 5. Calculate and print the average BLEU score\n",
        "if bleu_scores:\n",
        "    average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "    print(f\"\\n--- Overall Performance ---\")\n",
        "    print(f\"Average BLEU Score across {len(test_cases)} test cases: {average_bleu_score:.4f}\")\n",
        "else:\n",
        "    print(\"No test cases to evaluate.\")"
      ],
      "id": "bdf6f03d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb8416d1"
      },
      "source": [
        "### Chatbot Architectural Diagram\n"
      ],
      "id": "bb8416d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fc72b86"
      },
      "source": [
        "```mermaid\n",
        "graph TD\n",
        "    A[User] -->|Input Text| B(User Interface);\n",
        "    B -->|User Input| C[Intent Recognizer];\n",
        "    B -->|User Input| D[Entity Extractor];\n",
        "\n",
        "    C -->|Identified Intent| E{Context Manager};\n",
        "    D -->|Extracted Entities| E;\n",
        "\n",
        "    E -->|Contextualized Info| F[Response Generator];\n",
        "\n",
        "    subgraph External Resources\n",
        "        G[Pre-trained NLP Models] --> C;\n",
        "        H[SpaCy Model] --> D;\n",
        "        I[Response Templates/Knowledge Base] --> F;\n",
        "    end\n",
        "\n",
        "    F -->|Chatbot Response| B;\n",
        "    B -->|Display Response| A;\n",
        "\n",
        "    style A fill:#f9f,stroke:#333,stroke-width:2px;\n",
        "    style B fill:#bbf,stroke:#333,stroke-width:2px;\n",
        "    style C fill:#ccf,stroke:#333,stroke-width:2px;\n",
        "    style D fill:#cfc,stroke:#333,stroke-width:2px;\n",
        "    style E fill:#ffc,stroke:#333,stroke-width:2px;\n",
        "    style F fill:#fcf,stroke:#333,stroke-width:2px;\n",
        "    style G fill:#eee,stroke:#333,stroke-width:2px;\n",
        "    style H fill:#eee,stroke:#333,stroke-width:2px;\n",
        "    style I fill:#eee,stroke:#333,stroke-width:2px;\n",
        "```"
      ],
      "id": "2fc72b86"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a6b33bd"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed because NLTK's `word_tokenize` implicitly requires the `punkt_tab` resource, which was not downloaded. The error message explicitly suggests downloading `punkt_tab`. I will modify the previous `nltk.download` command to include `punkt_tab`.\n",
        "\n"
      ],
      "id": "1a6b33bd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd7386b"
      },
      "source": [
        "get_ipython().system('pip install nltk')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "print(\"NLTK and punkt tokenizer downloaded and ready for use.\")"
      ],
      "id": "efd7386b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6f1556"
      },
      "source": [
        "**Reasoning**:\n",
        "With `punkt_tab` now downloaded, the previous code to evaluate the chatbot using BLEU scores should now execute without a `LookupError`. I will re-run the evaluation code to generate and display the performance metrics.\n",
        "\n"
      ],
      "id": "af6f1556"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd03517c"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 2. Create a list of test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"user_input\": \"Hello, I'd like to book an appointment.\",\n",
        "        \"reference_response\": \"When would you like to book? What date would you prefer?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I want it for next Tuesday.\",\n",
        "        \"reference_response\": \"When would you like to book? How about next Tuesday?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I'm looking for an iPhone.\",\n",
        "        \"reference_response\": \"Which product are you interested in?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Goodbye.\",\n",
        "        \"reference_response\": \"Have a great day!\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"What is the weather like?\",\n",
        "        \"reference_response\": \"I'm not sure I understand that.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I need help with my laptop.\",\n",
        "        \"reference_response\": \"How can I assist you with support? Please describe your issue.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Can you book a meeting for tomorrow?\",\n",
        "        \"reference_response\": \"When would you like to book? How about tomorrow?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 3. Define an evaluation function\n",
        "def evaluate_chatbot(test_case):\n",
        "    user_input = test_case[\"user_input\"]\n",
        "    reference_response = test_case[\"reference_response\"]\n",
        "\n",
        "    # Use a fresh history for each test case to avoid cross-contamination\n",
        "    current_conversation_history = []\n",
        "    chatbot_actual_response = chatbot_response(user_input, current_conversation_history)\n",
        "\n",
        "    # Tokenize responses for BLEU score calculation\n",
        "    # The reference is a list of lists of tokens (or single list if only one reference)\n",
        "    # The candidate is a single list of tokens\n",
        "    reference_tokens = [word_tokenize(reference_response.lower())]\n",
        "    candidate_tokens = word_tokenize(chatbot_actual_response.lower())\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    # Weights are for 1-gram, 2-gram, 3-gram, 4-gram. Adjust as needed.\n",
        "    # For short sentences, using higher order n-grams might result in 0.0 scores.\n",
        "    # Using uniform weights for simplicity.\n",
        "    score = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    return chatbot_actual_response, score\n",
        "\n",
        "# 4. Iterate through the test cases and print BLEU scores\n",
        "bleu_scores = []\n",
        "print(\"--- Chatbot Evaluation Results ---\")\n",
        "for i, tc in enumerate(test_cases):\n",
        "    actual_response, score = evaluate_chatbot(tc)\n",
        "    bleu_scores.append(score)\n",
        "    print(f\"\\nTest Case {i+1}:\")\n",
        "    print(f\"  User Input: '{tc['user_input']}'\")\n",
        "    print(f\"  Reference:  '{tc['reference_response']}'\")\n",
        "    print(f\"  Chatbot:    '{actual_response}'\")\n",
        "    print(f\"  BLEU Score: {score:.4f}\")\n",
        "\n",
        "# 5. Calculate and print the average BLEU score\n",
        "if bleu_scores:\n",
        "    average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "    print(f\"\\n--- Overall Performance ---\")\n",
        "    print(f\"Average BLEU Score across {len(test_cases)} test cases: {average_bleu_score:.4f}\")\n",
        "else:\n",
        "    print(\"No test cases to evaluate.\")"
      ],
      "id": "dd03517c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5de8982c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous evaluation showed low BLEU scores for some test cases due to incorrect intent prioritization and lack of conversation history during evaluation. I will reorder the intent checks in `recognize_intent` to prioritize 'support' correctly and modify the evaluation loop to pass a persistent `conversation_history` to `chatbot_response` to enable proper context management across test cases. After these fixes, I will re-run the evaluation.\n",
        "\n"
      ],
      "id": "5de8982c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19802865"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Existing responses dictionary (unchanged)\n",
        "responses = {\n",
        "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Welcome!\"],\n",
        "    \"booking\": [\"Sure! What date would you prefer?\", \"When would you like to book?\"],\n",
        "    \"farewell\": [\"Goodbye!\", \"Have a great day!\"],\n",
        "    \"product_inquiry\": [\"Which product are you interested in?\", \"Tell me more about the product you're looking for.\"],\n",
        "    \"support\": [\"How can I assist you with support?\", \"Please describe your issue.\"],\n",
        "    \"unknown\": [\"I'm not sure I understand that.\"]\n",
        "}\n",
        "\n",
        "# Modified recognize_intent to prioritize 'support' over 'product_inquiry'\n",
        "def recognize_intent(user_input):\n",
        "    user_input_lower = user_input.lower()\n",
        "    # Prioritize more specific intents first\n",
        "    if \"book\" in user_input_lower or \"appointment\" in user_input_lower:\n",
        "        return \"booking\"\n",
        "    elif \"support\" in user_input_lower or \"help\" in user_input_lower or \"issue\" in user_input_lower:\n",
        "        return \"support\"\n",
        "    elif \"product\" in user_input_lower or \"item\" in user_input_lower or \"iphone\" in user_input_lower or \"laptop\" in user_input_lower:\n",
        "        return \"product_inquiry\"\n",
        "    elif \"hello\" in user_input_lower or \"hi\" in user_input_lower:\n",
        "        return \"greeting\"\n",
        "    elif \"bye\" in user_input_lower or \"goodbye\" in user_input_lower:\n",
        "        return \"farewell\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Existing extract_entities function (unchanged)\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(user_input):\n",
        "    doc = nlp(user_input)\n",
        "    entities = {}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ not in entities:\n",
        "            entities[ent.label_] = []\n",
        "        entities[ent.label_].append(ent.text)\n",
        "    return entities\n",
        "\n",
        "# Existing chatbot_response function (unchanged, as its logic is correct for context)\n",
        "def chatbot_response(user_input, history):\n",
        "    current_intent = recognize_intent(user_input)\n",
        "    current_entities = extract_entities(user_input)\n",
        "\n",
        "    # Determine effective intent, considering history\n",
        "    effective_intent = current_intent\n",
        "    if current_intent == \"unknown\" and history:\n",
        "        last_user_entry = None\n",
        "        for entry in reversed(history): # Iterate backwards to find the last user input\n",
        "            if entry[\"role\"] == \"user\":\n",
        "                last_user_entry = entry\n",
        "                break\n",
        "        if last_user_entry:\n",
        "            last_user_intent = recognize_intent(last_user_entry[\"text\"])\n",
        "            # If the last user input had a booking intent and current input has a DATE entity, assume booking\n",
        "            if last_user_intent == \"booking\" and \"DATE\" in current_entities:\n",
        "                effective_intent = \"booking\"\n",
        "            # If the last user input had a product inquiry intent and current input has a PRODUCT/NORP entity, assume product_inquiry\n",
        "            elif last_user_intent == \"product_inquiry\" and (\"PRODUCT\" in current_entities or \"NORP\" in current_entities):\n",
        "                effective_intent = \"product_inquiry\"\n",
        "\n",
        "    # Append current user input to history\n",
        "    history.append({\"role\": \"user\", \"text\": user_input})\n",
        "\n",
        "    response_text = random.choice(responses.get(effective_intent, responses[\"unknown\"])) # Default response based on effective intent\n",
        "\n",
        "    # Logic for booking intent\n",
        "    if effective_intent == \"booking\":\n",
        "        date_found = False\n",
        "        date = None\n",
        "        if \"DATE\" in current_entities:\n",
        "            date = current_entities[\"DATE\"][0]\n",
        "            response_text = random.choice(responses[\"booking\"]) + f\" How about {date}?\"\n",
        "            date_found = True\n",
        "        elif not date_found:\n",
        "            # Check conversation history for a date if not found in current or current_entities\n",
        "            # Exclude the very last entry (current user input) from history search for previous date\n",
        "            for entry in reversed(history[:-1]):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"DATE\" in prev_entities:\n",
        "                        date = prev_entities[\"DATE\"][0]\n",
        "                        response_text = random.choice(responses[\"booking\"]) + f\" Based on our previous chat, how about {date}?\"\n",
        "                        date_found = True\n",
        "                        break\n",
        "            if not date_found:\n",
        "                response_text = random.choice(responses[\"booking\"]) + \" What date would you prefer?\"\n",
        "\n",
        "    # Logic for product inquiry intent\n",
        "    elif effective_intent == \"product_inquiry\":\n",
        "        product = None\n",
        "        if \"PRODUCT\" in current_entities:\n",
        "            product = current_entities[\"PRODUCT\"][0]\n",
        "        elif \"NORP\" in current_entities: # Sometimes product names might be tagged as NORP (Nationalities, Religious or Political Groups) or other entities if SpaCy doesn't know them.\n",
        "            product = current_entities[\"NORP\"][0]\n",
        "        else: # Check history for product if not found in current or current_entities\n",
        "             for entry in reversed(history[:-1]):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"PRODUCT\" in prev_entities:\n",
        "                        product = prev_entities[\"PRODUCT\"][0]\n",
        "                        break\n",
        "                    elif \"NORP\" in prev_entities: # Also check for NORP in history for product names\n",
        "                        product = prev_entities[\"NORP\"][0]\n",
        "                        break\n",
        "\n",
        "        if product:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"]) + f\" Can you tell me more about the {product}?\"\n",
        "        else:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"])\n",
        "    elif effective_intent == \"support\":\n",
        "        response_text = random.choice(responses[\"support\"])\n",
        "\n",
        "    # Append chatbot response to history\n",
        "    history.append({\"role\": \"chatbot\", \"text\": response_text})\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# 2. Create a list of test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"user_input\": \"Hello, I'd like to book an appointment.\",\n",
        "        \"reference_response\": \"When would you like to book? What date would you prefer?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I want it for next Tuesday.\",\n",
        "        \"reference_response\": \"When would you like to book? How about next Tuesday?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I'm looking for an iPhone.\",\n",
        "        \"reference_response\": \"Which product are you interested in?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Goodbye.\",\n",
        "        \"reference_response\": \"Have a great day!\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"What is the weather like?\",\n",
        "        \"reference_response\": \"I'm not sure I understand that.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I need help with my laptop.\",\n",
        "        \"reference_response\": \"How can I assist you with support? Please describe your issue.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Can you book a meeting for tomorrow?\",\n",
        "        \"reference_response\": \"When would you like to book? How about tomorrow?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# 3. Define an evaluation function that maintains history\n",
        "def evaluate_chatbot_with_history(test_case, history):\n",
        "    user_input = test_case[\"user_input\"]\n",
        "    reference_response = test_case[\"reference_response\"]\n",
        "\n",
        "    chatbot_actual_response = chatbot_response(user_input, history) # Pass history to chatbot_response\n",
        "\n",
        "    # Tokenize responses for BLEU score calculation\n",
        "    reference_tokens = [word_tokenize(reference_response.lower())]\n",
        "    candidate_tokens = word_tokenize(chatbot_actual_response.lower())\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    # Using uniform weights for simplicity.\n",
        "    score = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    return chatbot_actual_response, score\n",
        "\n",
        "# 4. Iterate through the test cases and print BLEU scores\n",
        "bleu_scores = []\n",
        "# Initialize conversation history for evaluation, persistent across test cases\n",
        "evaluation_conversation_history = []\n",
        "print(\"--- Chatbot Evaluation Results ---\")\n",
        "for i, tc in enumerate(test_cases):\n",
        "    actual_response, score = evaluate_chatbot_with_history(tc, evaluation_conversation_history) # Call evaluation function with history\n",
        "    bleu_scores.append(score)\n",
        "    print(f\"\\nTest Case {i+1}:\")\n",
        "    print(f\"  User Input: '{tc['user_input']}'\")\n",
        "    print(f\"  Reference:  '{tc['reference_response']}'\")\n",
        "    print(f\"  Chatbot:    '{actual_response}'\")\n",
        "    print(f\"  BLEU Score: {score:.4f}\")\n",
        "\n",
        "# 5. Calculate and print the average BLEU score\n",
        "if bleu_scores:\n",
        "    average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "    print(f\"\\n--- Overall Performance ---\")\n",
        "    print(f\"Average BLEU Score across {len(test_cases)} test cases: {average_bleu_score:.4f}\")\n",
        "else:\n",
        "    print(\"No test cases to evaluate.\")"
      ],
      "id": "19802865",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510574c0"
      },
      "source": [
        "**Reasoning**:\n",
        "To fully address the subtask of evaluating chatbot performance, I will introduce another common metric: ROUGE scores. This involves installing the `rouge_score` library and modifying the `evaluate_chatbot_with_history` function to calculate and display both BLEU and ROUGE scores for each test case, along with their averages.\n",
        "\n"
      ],
      "id": "510574c0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "180168fe"
      },
      "source": [
        "get_ipython().system('pip install rouge_score')\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "import random\n",
        "import spacy\n",
        "\n",
        "# Existing responses dictionary (unchanged)\n",
        "responses = {\n",
        "    \"greeting\": [\"Hello!\", \"Hi there!\", \"Welcome!\"],\n",
        "    \"booking\": [\"Sure! What date would you prefer?\", \"When would you like to book?\"],\n",
        "    \"farewell\": [\"Goodbye!\", \"Have a great day!\"],\n",
        "    \"product_inquiry\": [\"Which product are you interested in?\", \"Tell me more about the product you're looking for.\"],\n",
        "    \"support\": [\"How can I assist you with support?\", \"Please describe your issue.\"],\n",
        "    \"unknown\": [\"I'm not sure I understand that.\"]\n",
        "}\n",
        "\n",
        "# Modified recognize_intent to prioritize 'support' over 'product_inquiry'\n",
        "def recognize_intent(user_input):\n",
        "    user_input_lower = user_input.lower()\n",
        "    # Prioritize more specific intents first\n",
        "    if \"book\" in user_input_lower or \"appointment\" in user_input_lower:\n",
        "        return \"booking\"\n",
        "    elif \"support\" in user_input_lower or \"help\" in user_input_lower or \"issue\" in user_input_lower:\n",
        "        return \"support\"\n",
        "    elif \"product\" in user_input_lower or \"item\" in user_input_lower or \"iphone\" in user_input_lower or \"laptop\" in user_input_lower:\n",
        "        return \"product_inquiry\"\n",
        "    elif \"hello\" in user_input_lower or \"hi\" in user_input_lower:\n",
        "        return \"greeting\"\n",
        "    elif \"bye\" in user_input_lower or \"goodbye\" in user_input_lower:\n",
        "        return \"farewell\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Existing extract_entities function (unchanged)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(user_input):\n",
        "    doc = nlp(user_input)\n",
        "    entities = {}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ not in entities:\n",
        "            entities[ent.label_] = []\n",
        "        entities[ent.label_].append(ent.text)\n",
        "    return entities\n",
        "\n",
        "# Existing chatbot_response function (unchanged, as its logic is correct for context)\n",
        "def chatbot_response(user_input, history):\n",
        "    current_intent = recognize_intent(user_input)\n",
        "    current_entities = extract_entities(user_input)\n",
        "\n",
        "    # Determine effective intent, considering history\n",
        "    effective_intent = current_intent\n",
        "    if current_intent == \"unknown\" and history:\n",
        "        last_user_entry = None\n",
        "        for entry in reversed(history): # Iterate backwards to find the last user input\n",
        "            if entry[\"role\"] == \"user\":\n",
        "                last_user_entry = entry\n",
        "                break\n",
        "        if last_user_entry:\n",
        "            last_user_intent = recognize_intent(last_user_entry[\"text\"])\n",
        "            # If the last user input had a booking intent and current input has a DATE entity, assume booking\n",
        "            if last_user_intent == \"booking\" and \"DATE\" in current_entities:\n",
        "                effective_intent = \"booking\"\n",
        "            # If the last user input had a product inquiry intent and current input has a PRODUCT/NORP entity, assume product_inquiry\n",
        "            elif last_user_intent == \"product_inquiry\" and (\"PRODUCT\" in current_entities or \"NORP\" in current_entities):\n",
        "                effective_intent = \"product_inquiry\"\n",
        "\n",
        "    # Append current user input to history\n",
        "    history.append({\"role\": \"user\", \"text\": user_input})\n",
        "\n",
        "    response_text = random.choice(responses.get(effective_intent, responses[\"unknown\"])) # Default response based on effective intent\n",
        "\n",
        "    # Logic for booking intent\n",
        "    if effective_intent == \"booking\":\n",
        "        date_found = False\n",
        "        date = None\n",
        "        if \"DATE\" in current_entities:\n",
        "            date = current_entities[\"DATE\"][0]\n",
        "            response_text = random.choice(responses[\"booking\"]) + f\" How about {date}?\"\n",
        "            date_found = True\n",
        "        elif not date_found:\n",
        "            # Check conversation history for a date if not found in current or current_entities\n",
        "            # Exclude the very last entry (current user input) from history search for previous date\n",
        "            for entry in reversed(history[:-1]):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"DATE\" in prev_entities:\n",
        "                        date = prev_entities[\"DATE\"][0]\n",
        "                        response_text = random.choice(responses[\"booking\"]) + f\" Based on our previous chat, how about {date}?\"\n",
        "                        date_found = True\n",
        "                        break\n",
        "            if not date_found:\n",
        "                response_text = random.choice(responses[\"booking\"]) + \" What date would you prefer?\"\n",
        "\n",
        "    # Logic for product inquiry intent\n",
        "    elif effective_intent == \"product_inquiry\":\n",
        "        product = None\n",
        "        if \"PRODUCT\" in current_entities:\n",
        "            product = current_entities[\"PRODUCT\"][0]\n",
        "        elif \"NORP\" in current_entities: # Sometimes product names might be tagged as NORP (Nationalities, Religious or Political Groups) or other entities if SpaCy doesn't know them.\n",
        "            product = current_entities[\"NORP\"][0]\n",
        "        else: # Check history for product if not found in current or current_entities\n",
        "             for entry in reversed(history[:-1]):\n",
        "                if entry[\"role\"] == \"user\":\n",
        "                    prev_entities = extract_entities(entry[\"text\"])\n",
        "                    if \"PRODUCT\" in prev_entities:\n",
        "                        product = prev_entities[\"PRODUCT\"][0]\n",
        "                        break\n",
        "                    elif \"NORP\" in prev_entities: # Also check for NORP in history for product names\n",
        "                        product = prev_entities[\"NORP\"][0]\n",
        "                        break\n",
        "\n",
        "        if product:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"]) + f\" Can you tell me more about the {product}?\"\n",
        "        else:\n",
        "             response_text = random.choice(responses[\"product_inquiry\"])\n",
        "    elif effective_intent == \"support\":\n",
        "        response_text = random.choice(responses[\"support\"])\n",
        "\n",
        "    # Append chatbot response to history\n",
        "    history.append({\"role\": \"chatbot\", \"text\": response_text})\n",
        "\n",
        "    return response_text\n",
        "\n",
        "# 2. Create a list of test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"user_input\": \"Hello, I'd like to book an appointment.\",\n",
        "        \"reference_response\": \"When would you like to book? What date would you prefer?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I want it for next Tuesday.\",\n",
        "        \"reference_response\": \"When would you like to book? How about next Tuesday?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I'm looking for an iPhone.\",\n",
        "        \"reference_response\": \"Which product are you interested in?\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Goodbye.\",\n",
        "        \"reference_response\": \"Have a great day!\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"What is the weather like?\",\n",
        "        \"reference_response\": \"I'm not sure I understand that.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"I need help with my laptop.\",\n",
        "        \"reference_response\": \"How can I assist you with support? Please describe your issue.\"\n",
        "    },\n",
        "    {\n",
        "        \"user_input\": \"Can you book a meeting for tomorrow?\",\n",
        "        \"reference_response\": \"When would you like to book? How about tomorrow?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# 3. Define an evaluation function that maintains history and calculates ROUGE\n",
        "def evaluate_chatbot_with_history_and_rouge(test_case, history):\n",
        "    user_input = test_case[\"user_input\"]\n",
        "    reference_response = test_case[\"reference_response\"]\n",
        "\n",
        "    chatbot_actual_response = chatbot_response(user_input, history) # Pass history to chatbot_response\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    reference_tokens = [word_tokenize(reference_response.lower())]\n",
        "    candidate_tokens = word_tokenize(chatbot_actual_response.lower())\n",
        "    bleu_score = sentence_bleu(reference_tokens, candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    # Calculate ROUGE scores\n",
        "    rouge_scores = scorer.score(reference_response, chatbot_actual_response)\n",
        "\n",
        "    return chatbot_actual_response, bleu_score, rouge_scores\n",
        "\n",
        "# 4. Iterate through the test cases and print BLEU and ROUGE scores\n",
        "bleu_scores = []\n",
        "rouge1_fmeasures = []\n",
        "rouge2_fmeasures = []\n",
        "rougeL_fmeasures = []\n",
        "\n",
        "# Initialize conversation history for evaluation, persistent across test cases\n",
        "evaluation_conversation_history = []\n",
        "print(\"--- Chatbot Evaluation Results ---\")\n",
        "for i, tc in enumerate(test_cases):\n",
        "    actual_response, bleu_score, rouge_scores = evaluate_chatbot_with_history_and_rouge(tc, evaluation_conversation_history) # Call evaluation function with history\n",
        "    bleu_scores.append(bleu_score)\n",
        "    rouge1_fmeasures.append(rouge_scores['rouge1'].fmeasure)\n",
        "    rouge2_fmeasures.append(rouge_scores['rouge2'].fmeasure)\n",
        "    rougeL_fmeasures.append(rouge_scores['rougeL'].fmeasure)\n",
        "\n",
        "    print(f\"\\nTest Case {i+1}:\")\n",
        "    print(f\"  User Input: '{tc['user_input']}'\")\n",
        "    print(f\"  Reference:  '{tc['reference_response']}'\")\n",
        "    print(f\"  Chatbot:    '{actual_response}'\")\n",
        "    print(f\"  BLEU Score: {bleu_score:.4f}\")\n",
        "    print(f\"  ROUGE-1 F1: {rouge_scores['rouge1'].fmeasure:.4f}\")\n",
        "    print(f\"  ROUGE-2 F1: {rouge_scores['rouge2'].fmeasure:.4f}\")\n",
        "    print(f\"  ROUGE-L F1: {rouge_scores['rougeL'].fmeasure:.4f}\")\n",
        "\n",
        "# 5. Calculate and print the average BLEU and ROUGE scores\n",
        "if bleu_scores:\n",
        "    average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "    average_rouge1 = sum(rouge1_fmeasures) / len(rouge1_fmeasures)\n",
        "    average_rouge2 = sum(rouge2_fmeasures) / len(rouge2_fmeasures)\n",
        "    average_rougeL = sum(rougeL_fmeasures) / len(rougeL_fmeasures)\n",
        "\n",
        "    print(f\"\\n--- Overall Performance ---\")\n",
        "    print(f\"Average BLEU Score across {len(test_cases)} test cases: {average_bleu_score:.4f}\")\n",
        "    print(f\"Average ROUGE-1 F1 Score: {average_rouge1:.4f}\")\n",
        "    print(f\"Average ROUGE-2 F1 Score: {average_rouge2:.4f}\")\n",
        "    print(f\"Average ROUGE-L F1 Score: {average_rougeL:.4f}\")\n",
        "else:\n",
        "    print(\"No test cases to evaluate.\")"
      ],
      "id": "180168fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57a6664a"
      },
      "source": [
        "print(\"Chatbot CLI. Type 'quit', 'exit', or 'bye' to end the conversation.\")\n",
        "\n",
        "# Initialize an empty list named conversation_history to store the dialogue.\n",
        "conversation_history = []\n",
        "\n",
        "# Create an infinite loop for continuous interaction\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Check for termination commands\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Call the chatbot_response function with the user's input and the conversation_history list\n",
        "    chatbot_output = chatbot_response(user_input, conversation_history)\n",
        "\n",
        "    # Print the chatbot's response\n",
        "    print(f\"Chatbot: {chatbot_output}\")\n",
        "\n",
        "    # (Optional) Print the current state of the conversation_history\n",
        "    # print(\"\\n--- Conversation History ---\")\n",
        "    # for entry in conversation_history:\n",
        "    #     print(f\"{entry['role'].capitalize()}: {entry['text']}\")\n",
        "    # print(\"---------------------------\\n\")\n"
      ],
      "id": "57a6664a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beed93d5"
      },
      "source": [
        "## Create README, Project Name, and Description\n",
        "\n",
        "### Subtask:\n",
        "Generate a comprehensive README for GitHub, including a suitable project name and description.\n"
      ],
      "id": "beed93d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc62afdb"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate the README as requested by the subtask, I will define a multi-line string variable named `project_readme` containing all the specified sections and information for the chatbot project. This will be done in a new Python code cell.\n",
        "\n"
      ],
      "id": "bc62afdb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e47840c3"
      },
      "source": [
        "project_readme = \"\"\"# Conversational AI Chatbot\\n\\n## Project Description\\nThis project implements a sophisticated conversational AI chatbot designed to understand user intent, extract key entities from their queries, and maintain conversation context for more coherent and natural interactions. It serves as a foundational example of building intelligent dialogue systems using modern NLP techniques.\\n\\n## Features\\n*   **Intent Recognition**: Identifies the user's underlying goal (e.g., 'booking', 'product_inquiry', 'support') to provide relevant responses.\\n*   **Entity Extraction**: Utilizes SpaCy to pinpoint and extract crucial information like dates, products, or specific issues from user inputs.\\n*   **Conversation Context Management**: Remembers previous turns in the conversation to handle follow-up questions and incomplete requests intelligently.\\n*   **Response Generation**: Generates appropriate and contextually relevant responses based on recognized intent and extracted entities.\\n*   **Performance Evaluation**: Includes methods for evaluating chatbot performance using metrics like BLEU and ROUGE scores.\\n*   **Interactive Command-Line Interface (CLI)**: A simple interface for real-time interaction with the chatbot.\\n\\n## Technologies and Libraries Used\\n*   **Python**: The core programming language.\\n*   **SpaCy**: For advanced Natural Language Processing, specifically for entity extraction (`en_core_web_sm` model).\\n*   **NLTK**: Used for text tokenization, which is essential for calculating BLEU scores.\\n*   **rouge_score**: For calculating ROUGE metrics to evaluate response quality.\\n*   **random**: For selecting random responses from predefined lists.\\n*   **transformers (Hugging Face)**: Although not directly used in the final rule-based/contextual chatbot, it was explored for advanced response generation demonstrating its capabilities.\\n\\n## Setup and Installation\\nTo set up and run the chatbot, follow these steps:\\n\\n1.  **Clone the repository (or save the notebook)**:\\n    ```bash\\n    # If it were a repository\\n    # git clone <repository_url>\\n    # cd conversational-ai-chatbot\\n    ```\\n\\n2.  **Install dependencies**:\\n    Ensure you have Python 3.8+ installed. Then, install the required libraries:\\n    ```bash\\n    pip install spacy nltk rouge_score\\n    python -m spacy download en_core_web_sm\\n    ```\\n\\n3.  **Run the Chatbot CLI**:\\n    Execute the Python script (or the relevant cells in the notebook) that contains the `chatbot_response` function and the CLI loop.\\n    ```bash\\n    # Assuming your chatbot code is in a file named chatbot_cli.py\\n    # python chatbot_cli.py\\n    ```\\n    In this notebook, you would run the final code cell that starts the interactive loop.\\n\\n## How to Interact with the Chatbot\\nOnce the chatbot CLI is running:\\n\\n*   Type your messages in the prompt and press Enter.\\n*   The chatbot will respond based on its understanding of your intent and extracted entities.\\n*   To end the conversation, type `quit`, `exit`, or `bye` and press Enter.\\n\\n### Example Interactions:\\n```\\nChatbot CLI. Type 'quit', 'exit', or 'bye' to end the conversation.\\nYou: Hello, I'd like to book an appointment.\\nChatbot: When would you like to book? What date would you prefer?\\nYou: I want it for next Tuesday.\\nChatbot: When would you like to book? How about next Tuesday?\\nYou: I'm looking for an iPhone.\\nChatbot: Which product are you interested in?\\nYou: I need help with my laptop.\\nChatbot: How can I assist you with support? Please describe your issue.\\nYou: Goodbye.\\nChatbot: Goodbye!\\n```\\n\"\"\""
      ],
      "id": "e47840c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51e67e36"
      },
      "source": [
        "# Conversational AI Chatbot\n",
        "\n",
        "## Project Description\n",
        "This project implements a sophisticated conversational AI chatbot designed to understand user intent, extract key entities from their queries, and maintain conversation context for more coherent and natural interactions. It serves as a foundational example of building intelligent dialogue systems using modern NLP techniques.\n",
        "\n",
        "## Features\n",
        "*   **Intent Recognition**: Identifies the user's underlying goal (e.g., 'booking', 'product_inquiry', 'support') to provide relevant responses.\n",
        "*   **Entity Extraction**: Utilizes SpaCy to pinpoint and extract crucial information like dates, products, or specific issues from user inputs.\n",
        "*   **Conversation Context Management**: Remembers previous turns in the conversation to handle follow-up questions and incomplete requests intelligently.\n",
        "*   **Response Generation**: Generates appropriate and contextually relevant responses based on recognized intent and extracted entities.\n",
        "*   **Performance Evaluation**: Includes methods for evaluating chatbot performance using metrics like BLEU and ROUGE scores.\n",
        "*   **Interactive Command-Line Interface (CLI)**: A simple interface for real-time interaction with the chatbot.\n",
        "\n",
        "## Technologies and Libraries Used\n",
        "*   **Python**: The core programming language.\n",
        "*   **SpaCy**: For advanced Natural Language Processing, specifically for entity extraction (`en_core_web_sm` model).\n",
        "*   **NLTK**: Used for text tokenization, which is essential for calculating BLEU scores.\n",
        "*   **rouge_score**: For calculating ROUGE metrics to evaluate response quality.\n",
        "*   **random**: For selecting random responses from predefined lists.\n",
        "*   **transformers (Hugging Face)**: Although not directly used in the final rule-based/contextual chatbot, it was explored for advanced response generation demonstrating its capabilities.\n",
        "\n",
        "## Setup and Installation\n",
        "To set up and run the chatbot, follow these steps:\n",
        "\n",
        "1.  **Clone the repository (or save the notebook)**:\n",
        "    ```bash\n",
        "    # If it were a repository\n",
        "    # git clone <repository_url>\n",
        "    # cd conversational-ai-chatbot\n",
        "    ```\n",
        "\n",
        "2.  **Install dependencies**:\n",
        "    Ensure you have Python 3.8+ installed. Then, install the required libraries:\n",
        "    ```bash\n",
        "    pip install spacy nltk rouge_score\n",
        "    python -m spacy download en_core_web_sm\n",
        "    ```\n",
        "\n",
        "3.  **Run the Chatbot CLI**:\n",
        "    Execute the Python script (or the relevant cells in the notebook) that contains the `chatbot_response` function and the CLI loop.\n",
        "    ```bash\n",
        "    # Assuming your chatbot code is in a file named chatbot_cli.py\n",
        "    # python chatbot_cli.py\n",
        "    ```\n",
        "    In this notebook, you would run the final code cell that starts the interactive loop.\n",
        "\n",
        "## How to Interact with the Chatbot\n",
        "Once the chatbot CLI is running:\n",
        "\n",
        "*   Type your messages in the prompt and press Enter.\n",
        "*   The chatbot will respond based on its understanding of your intent and extracted entities.\n",
        "*   To end the conversation, type `quit`, `exit`, or `bye` and press Enter.\n",
        "\n",
        "### Example Interactions:\n",
        "```\n",
        "Chatbot CLI. Type 'quit', 'exit', or 'bye' to end the conversation.\n",
        "You: Hello, I'd like to book an appointment.\n",
        "Chatbot: When would you like to book? What date would you prefer?\n",
        "You: I want it for next Tuesday.\n",
        "Chatbot: When would you like to book? How about next Tuesday?\n",
        "You: I'm looking for an iPhone.\n",
        "Chatbot: Which product are you interested in?\n",
        "You: I need help with my laptop.\n",
        "Chatbot: How can I assist you with support? Please describe your issue.\n",
        "You: Goodbye.\n",
        "Chatbot: Goodbye!\n",
        "```"
      ],
      "id": "51e67e36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a68a3373"
      },
      "source": [
        "# Conversational AI Chatbot\n",
        "\n",
        "## Project Description\n",
        "This project implements a sophisticated conversational AI chatbot designed to understand user intent, extract key entities from their queries, and maintain conversation context for more coherent and natural interactions. It serves as a foundational example of building intelligent dialogue systems using modern NLP techniques.\n",
        "\n",
        "## Features\n",
        "*   **Intent Recognition**: Identifies the user's underlying goal (e.g., 'booking', 'product_inquiry', 'support') to provide relevant responses.\n",
        "*   **Entity Extraction**: Utilizes SpaCy to pinpoint and extract crucial information like dates, products, or specific issues from user inputs.\n",
        "*   **Conversation Context Management**: Remembers previous turns in the conversation to handle follow-up questions and incomplete requests intelligently.\n",
        "*   **Response Generation**: Generates appropriate and contextually relevant responses based on recognized intent and extracted entities.\n",
        "*   **Performance Evaluation**: Includes methods for evaluating chatbot performance using metrics like BLEU and ROUGE scores.\n",
        "*   **Interactive Command-Line Interface (CLI)**: A simple interface for real-time interaction with the chatbot.\n",
        "\n",
        "## Technologies and Libraries Used\n",
        "*   **Python**: The core programming language.\n",
        "*   **SpaCy**: For advanced Natural Language Processing, specifically for entity extraction (`en_core_web_sm` model).\n",
        "*   **NLTK**: Used for text tokenization, which is essential for calculating BLEU scores.\n",
        "*   **rouge_score**: For calculating ROUGE metrics to evaluate response quality.\n",
        "*   **random**: For selecting random responses from predefined lists.\n",
        "*   **transformers (Hugging Face)**: Although not directly used in the final rule-based/contextual chatbot, it was explored for advanced response generation demonstrating its capabilities.\n",
        "\n",
        "## Setup and Installation\n",
        "To set up and run the chatbot, follow these steps:\n",
        "\n",
        "1.  **Clone the repository (or save the notebook)**:\n",
        "    ```bash\n",
        "    # If it were a repository\n",
        "    # git clone <repository_url>\n",
        "    # cd conversational-ai-chatbot\n",
        "    ```\n",
        "\n",
        "2.  **Install dependencies**:\n",
        "    Ensure you have Python 3.8+ installed. Then, install the required libraries:\n",
        "    ```bash\n",
        "    pip install spacy nltk rouge_score\n",
        "    python -m spacy download en_core_web_sm\n",
        "    ```\n",
        "\n",
        "3.  **Run the Chatbot CLI**:\n",
        "    Execute the Python script (or the relevant cells in the notebook) that contains the `chatbot_response` function and the CLI loop.\n",
        "    ```bash\n",
        "    # Assuming your chatbot code is in a file named chatbot_cli.py\n",
        "    # python chatbot_cli.py\n",
        "    ```\n",
        "    In this notebook, you would run the final code cell that starts the interactive loop.\n",
        "\n",
        "## How to Interact with the Chatbot\n",
        "Once the chatbot CLI is running:\n",
        "\n",
        "*   Type your messages in the prompt and press Enter.\n",
        "*   The chatbot will respond based on its understanding of your intent and extracted entities.\n",
        "*   To end the conversation, type `quit`, `exit`, or `bye` and press Enter.\n",
        "\n",
        "### Example Interactions:\n",
        "```\n",
        "Chatbot CLI. Type 'quit', 'exit', or 'bye' to end the conversation.\n",
        "You: Hello, I'd like to book an appointment.\n",
        "Chatbot: When would you like to book? What date would you prefer?\n",
        "You: I want it for next Tuesday.\n",
        "Chatbot: When would you like to book? How about next Tuesday?\n",
        "You: I'm looking for an iPhone.\n",
        "Chatbot: Which product are you interested in?\n",
        "You: I need help with my laptop.\n",
        "Chatbot: How can I assist you with support? Please describe your issue.\n",
        "You: Goodbye.\n",
        "Chatbot: Goodbye!\n",
        "```"
      ],
      "id": "a68a3373"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4139309"
      },
      "source": [
        "## Create Project Documentation and Presentation Assets\n",
        "\n",
        "### Subtask:\n",
        "Outline key elements for a good work presentation for the chatbot project.\n"
      ],
      "id": "a4139309"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a430eaff"
      },
      "source": [
        "## Create Project Documentation and Presentation Assets\n",
        "\n",
        "### Subtask:\n",
        "Outline key elements for a good work presentation for the chatbot project.\n",
        "\n",
        "#### Instructions\n",
        "1. Create a multi-line string variable named `presentation_outline`.\n",
        "2. Populate this variable with a structured outline for a presentation, covering key aspects of the chatbot project.\n",
        "3. The outline should include sections like 'Introduction', 'Problem Statement', 'Solution Overview', 'Technical Deep Dive (Intent Recognition, Entity Extraction, Context Management)', 'Performance Evaluation (Metrics & Results)', 'Interactive Demo', 'Future Work', and 'Q&A'."
      ],
      "id": "a430eaff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fcf7541"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask instructs to create a multi-line string variable named `presentation_outline` and populate it with a structured outline for the chatbot project presentation. I will create a code cell to define this variable with the specified content.\n",
        "\n"
      ],
      "id": "5fcf7541"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34268685"
      },
      "source": [
        "presentation_outline = \"\"\"# Chatbot Project Presentation Outline\\n\\n## 1. Introduction\\n*   Project Title and Presenter(s)\\n*   Brief overview of the chatbot's purpose and capabilities\\n\\n## 2. Problem Statement\\n*   What challenge does this chatbot address?\\n*   Why is an intelligent conversational agent needed?\\n\\n## 3. Solution Overview\\n*   High-level architecture of the chatbot system\\n*   Key components: Intent Recognition, Entity Extraction, Context Management, Response Generation\\n\\n## 4. Technical Deep Dive\\n### 4.1. Intent Recognition\\n*   How user intent is identified (e.g., keyword matching, classifier)\\n*   Examples of supported intents (booking, product inquiry, support)\\n### 4.2. Entity Extraction\\n*   Role of SpaCy in identifying entities (dates, products)\\n*   Demonstration of entity extraction in action\\n### 4.3. Context Management\\n*   How conversation history is maintained\\n*   Addressing follow-up questions and maintaining coherence\\n\\n## 5. Performance Evaluation\\n*   Metrics used: BLEU, ROUGE scores\\n*   Summary of evaluation results and their interpretation\\n*   Challenges and limitations of current evaluation\\n\\n## 6. Interactive Demo\\n*   Live demonstration of the chatbot's functionalities\\n*   Showcasing intent recognition, entity extraction, and context awareness\\n\\n## 7. Future Work\\n*   Potential enhancements: more advanced NLP models, broader domain coverage, voice integration\\n*   Deployment strategies and scalability considerations\\n\\n## 8. Q&A\\n*   Open floor for questions and discussion\\n\"\"\""
      ],
      "id": "34268685",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40458e22"
      },
      "source": [
        "## Design a Conceptual Architectural Diagram\n",
        "\n",
        "### Subtask:\n",
        "Design a conceptual architectural diagram illustrating the chatbot's architecture, including data flow and pipeline.\n"
      ],
      "id": "40458e22"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b8931a3"
      },
      "source": [
        "**Reasoning**:\n",
        "To design a conceptual architectural diagram, I will create a multi-line string variable containing the diagram represented in Mermaid syntax, illustrating the chatbot's architecture and data flow.\n",
        "\n"
      ],
      "id": "1b8931a3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b95140f"
      },
      "source": [
        "architectural_diagram = \"\"\"```mermaid\n",
        "graph TD\n",
        "    A[User] -->|Input Text| B(User Interface);\n",
        "    B -->|User Input| C[Intent Recognizer];\n",
        "    B -->|User Input| D[Entity Extractor];\n",
        "\n",
        "    C -->|Identified Intent| E{Context Manager};\n",
        "    D -->|Extracted Entities| E;\n",
        "\n",
        "    E -->|Contextualized Info| F[Response Generator];\n",
        "\n",
        "    subgraph External Resources\n",
        "        G[Pre-trained NLP Models] --&gt; C;\n",
        "        H[SpaCy Model] --&gt; D;\n",
        "        I[Response Templates/Knowledge Base] --&gt; F;\n",
        "    end\n",
        "\n",
        "    F -->|Chatbot Response| B;\n",
        "    B -->|Display Response| A;\n",
        "\n",
        "    style A fill:#f9f,stroke:#333,stroke-width:2px;\n",
        "    style B fill:#bbf,stroke:#333,stroke-width:2px;\n",
        "    style C fill:#ccf,stroke:#333,stroke-width:2px;\n",
        "    style D fill:#cfc,stroke:#333,stroke-width:2px;\n",
        "    style E fill:#ffc,stroke:#333,stroke-width:2px;\n",
        "    style F fill:#fcf,stroke:#333,stroke-width:2px;\n",
        "    style G fill:#eee,stroke:#333,stroke-width:2px;\n",
        "    style H fill:#eee,stroke:#333,stroke-width:2px;\n",
        "    style I fill:#eee,stroke:#333,stroke-width:2px;\n",
        "```\"\"\"\n",
        "print(\"Architectural diagram variable created.\")"
      ],
      "id": "8b95140f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5d6a19c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review all the added components and documentation, ensuring the project is well-rounded, professionally presented, and ready for sharing.\n"
      ],
      "id": "b5d6a19c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad2d3da5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Intent Recognition and Entity Extraction:**\n",
        "    *   Initial keyword-based intent recognition showed limitations, misclassifying some user inputs (e.g., \"I need help with my product.\" as 'product\\_inquiry' instead of 'support').\n",
        "    *   SpaCy successfully extracted entities like \"tomorrow\" (DATE) and \"July 20th\" (DATE).\n",
        "    *   The integration of keyword-based intent recognition and SpaCy's entity extraction in initial tests resulted in some general responses due to limitations in the intent classification.\n",
        "*   **Conversation Context Management:**\n",
        "    *   The chatbot successfully maintained conversation history across turns, storing both user inputs and chatbot responses.\n",
        "    *   Refined logic in `recognize_intent` and `chatbot_response` improved context handling, allowing the chatbot to correctly interpret follow-up questions (e.g., interpreting \"next Tuesday\" as a date for a previously initiated booking).\n",
        "*   **Chatbot Performance Evaluation:**\n",
        "    *   The chatbot's performance was quantitatively assessed using BLEU and ROUGE metrics.\n",
        "    *   After refinements, the average BLEU Score was 0.5258.\n",
        "    *   The average ROUGE-1 F1 Score was 0.6314, ROUGE-2 F1 Score was 0.5659, and ROUGE-L F1 Score was 0.6314.\n",
        "*   **Simple Interactive User Interface:**\n",
        "    *   A functional command-line interface (CLI) was successfully developed, enabling continuous user interaction, displaying chatbot responses, and supporting termination commands.\n",
        "*   **Project Documentation and Presentation Assets:**\n",
        "    *   A comprehensive README file was generated, including project name (\"Conversational AI Chatbot\"), description, features, technologies, setup instructions, and example interactions.\n",
        "    *   A structured presentation outline was created, covering key project aspects from introduction to future work and Q\\&A.\n",
        "    *   A conceptual architectural diagram was designed using Mermaid syntax, illustrating the chatbot's components and data flow.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Enhance Intent Recognition with Machine Learning:** Transition from a keyword-based intent recognition system to a machine learning-based approach (e.g., using a small trained classifier with libraries like scikit-learn or even more advanced transformer models) to improve accuracy and reduce misclassifications for more nuanced user queries.\n",
        "*   **Integrate Human Evaluation for Response Quality:** While BLEU and ROUGE provide quantitative metrics, consider incorporating a framework for human evaluation to assess the naturalness, relevance, and overall helpfulness of the chatbot's responses, providing more qualitative insights for further improvements.\n"
      ],
      "id": "ad2d3da5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}